{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merlin Haslam PGD_DA Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Project Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code to create the Project Database\n",
    "## Do NOT run this code if the database already exists - unless you are starting the project from scratch\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "try:\n",
    "    dbConnection = psycopg2.connect(user = \"dap\",\n",
    "                                    password = \"dap\",\n",
    "                                    host = \"192.168.56.30\",\n",
    "                                    port = \"5432\",\n",
    "                                    database = \"postgres\")\n",
    "    dbConnection.set_isolation_level(0) # AUTOCOMMIT\n",
    "    dbCursor = dbConnection.cursor()\n",
    "    dbCursor.execute('DROP DATABASE IF EXISTS  GroupR_Project;')\n",
    "    dbCursor.execute('CREATE DATABASE GroupR_Project;')\n",
    "    dbCursor.close()\n",
    "except (Exception , psycopg2.Error) as dbError :\n",
    "    print (\"Error while connecting to PostgreSQL\", dbError)\n",
    "finally:\n",
    "    if(dbConnection):\n",
    "        dbConnection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating The Initial Table and Importing the CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code creates an initial table to store the PPR data\n",
    "## This datae is read into SQL text from the csv file via a pandas dataframe \n",
    "## The data is read from csv 100 records at a time\n",
    "## This code will read back an aggregated report of the counties in the data to demonstrate the data has been stored in the SQL database\n",
    "## This code should only be run once as it will delete the initial table if it already exists\n",
    "\n",
    "import psycopg2\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "#Create table script - drop if exists \n",
    "createppr_i = '''DROP TABLE IF EXISTS ppr_initial;\n",
    "CREATE TABLE ppr_initial\n",
    "(\n",
    "\"id\" serial primary key,\n",
    "dateofsale varchar (16),\n",
    "address varchar(128),\n",
    "postcode varchar(24),\n",
    "county varchar(24),\n",
    "price varchar(24),\n",
    "notfullprice varchar(8),\n",
    "vatexcl varchar(8),\n",
    "description varchar(128),\n",
    "sizedesc varchar(128)\n",
    "\n",
    ");'''\n",
    "\n",
    "readtable = '''Select County, count(*) as No_HousesSold \n",
    "from ppr_initial\n",
    "group by County;'''\n",
    "\n",
    "#Define the Connection to SQL - sqltype+conectiontype://user:pwd@address/database\n",
    "pgSQLengine   = create_engine('postgresql+psycopg2://dap:dap@192.168.56.30/groupr_project');\n",
    "#Name the Connection \n",
    "pgSQLconnection = pgSQLengine.connect();\n",
    "\n",
    "\n",
    "#Create that table\n",
    "pgSQLconnection.execute(createppr_i)\n",
    "\n",
    "\n",
    "pgSQLtable = \"ppr_initial\";\n",
    "\n",
    "\n",
    "try:\n",
    "    \n",
    "    for chunkofppr in pd.read_csv('PPR-ALL/PPR-ALL.CSV', \n",
    "                                  encoding='iso-8859-1', \n",
    "                                  header=0,\n",
    "                                  chunksize=100):\n",
    "            chunktoinsert = chunkofppr.rename(columns={'Date of Sale (dd/mm/yyyy)':'dateofsale','Address':'address',\n",
    "                                                       'Postal Code':'postcode','County':'county','Price (Â€)':'price',\n",
    "                                                       'Not Full Market Price':'notfullprice',\n",
    "                                                      'VAT Exclusive':'vatexcl','Description of Property':'description',\n",
    "                                                       'Property Size Description':'sizedesc'})\n",
    "            chunktoinsert.to_sql(pgSQLtable, pgSQLconnection, if_exists='append', index=False);\n",
    "\n",
    "except ValueError as verror:\n",
    "\n",
    "    print(verror)\n",
    "\n",
    "except Exception as xerror:  \n",
    "\n",
    "    print(xerror)\n",
    "\n",
    "else:\n",
    "\n",
    "    county_count = pgSQLconnection.execute(readtable)\n",
    "    for r in county_count:\n",
    "            print(r)\n",
    "\n",
    "finally:\n",
    "\n",
    "    \n",
    "    pgSQLconnection.close();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
